{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.util as ut\n",
    "import recomender.trivial as trivial\n",
    "import scripts.evaluate as eval\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate test and train\n",
    "test, train = ut.read_ratings()\n",
    "\n",
    "# put test in the same recomendation format\n",
    "test_recomendation = eval.test_to_recomendation(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_dict, train_item_dict, train_ratings_dict = train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_content():\n",
    "    with open(ut.CONTENT, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "\n",
    "    content_dict = {}\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        if (isinstance(result, dict)):\n",
    "            content_dict[result['ItemId']] = result   \n",
    "    return content_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_genre_dict(train_user_dict, content_dict):  \n",
    "  genre_dict = {}\n",
    "  for user_id in train_user_dict.keys():\n",
    "    genre_dict[user_id] = {}\n",
    "    items = train_user_dict[user_id]['Items']\n",
    "    for item in items:\n",
    "      genres = content_dict[item]['Genre'].split(', ')\n",
    "      for genre in genres:\n",
    "        if genre not in genre_dict[user_id]: genre_dict[user_id][genre] = []\n",
    "        genre_dict[user_id][genre].append(item)\n",
    "  return genre_dict\n",
    "genre_dict = make_genre_dict(train_user_dict, content_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00053f5e11', '199f8f5ff4', 7.5975889781859935]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rating_by_genre(user, item, ratings, content_dict, genre_dict):\n",
    "\n",
    "  genre_count = 1\n",
    "  rate_by_genre = 0\n",
    "  genres = content_dict[item]['Genre'].split(',')\n",
    "  for genre in genres:\n",
    "    if not genre in genre_dict[user]: continue\n",
    "    n_items = len(genre_dict[user][genre])\n",
    "    genre_rating = 0 \n",
    "    for genre_item in genre_dict[user][genre]:\n",
    "      genre_rating += ratings[user + ':' + genre_item]['Rating']\n",
    "    genre_rating = genre_rating/n_items\n",
    "    rate_by_genre += genre_rating\n",
    "    genre_count += 1\n",
    "  \n",
    "  return rate_by_genre, genre_count\n",
    "\n",
    "def genre_prediction(train, targets, content_dict):\n",
    "  train_user_dict, train_item_dict, train_ratings_dict = train\n",
    "  genre_dict = make_genre_dict(train_user_dict, content_dict)\n",
    "\n",
    "  mean_rating = 0\n",
    "  for key in train[2]:\n",
    "    mean_rating += train[2][key]['Rating']\n",
    "  mean_rating = mean_rating/len(train[2])\n",
    "\n",
    "  predictions = []\n",
    "  for pair in targets:\n",
    "    _tuser, _titem = pair.split(':')\n",
    "    dif_item_mean = 0\n",
    "    dif_rating = 0\n",
    "    weight = 1\n",
    "    if _titem in train_item_dict:\n",
    "      _item_dict = train_item_dict[_titem]\n",
    "      dif_item_mean = _item_dict['Rating_sum']/len(_item_dict['Users']) - mean_rating\n",
    "    \n",
    "      \n",
    "      if _tuser in train_user_dict: \n",
    "        dif_rating, weight = rating_by_genre(_tuser, _titem, train_ratings_dict, \n",
    "                                              content_dict, genre_dict) \n",
    "        if dif_rating > 0: dif_rating = dif_rating - mean_rating\n",
    "    \n",
    "    prediction = mean_rating + (dif_rating + dif_item_mean)/(weight) \n",
    "    if prediction < 0: break\n",
    "    predictions.append([_tuser, _titem, prediction])\n",
    "  \n",
    "  predictions = sorted(predictions, key=itemgetter(2), reverse=True)  \n",
    "  predictions = sorted(predictions, key=itemgetter(0), reverse=False)\n",
    "  return predictions\n",
    "predictions = genre_prediction(train, test[2].keys(), content_dict)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.969305466689108"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# External Imports\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "  # invert preference\n",
    "def invert_preference(expected_dict):\n",
    "  for user in expected_dict.keys():\n",
    "    for idx, pair in enumerate(expected_dict[user]):\n",
    "      item, relevance = pair\n",
    "      expected_dict[user][idx][1] = len(expected_dict[user]) - relevance \n",
    "  return expected_dict\n",
    "\n",
    "def invert_preference2(expected_dict, user_preference):\n",
    "  for pair in expected_dict.keys():\n",
    "    user, item = pair.split(',')\n",
    "    expected_dict[pair] = user_preference[user] - expected_dict[pair] \n",
    "    \n",
    "  return expected_dict\n",
    "\n",
    "def get_relevance(recomendation, expected):\n",
    "  expected_dict = {}\n",
    "  recomendation_dict = {}\n",
    "\n",
    "  # Create dict with user item and true relevance\n",
    "  user_relevance = {}\n",
    "  for pair in expected:\n",
    "    user, item = pair[:-1].split(',')\n",
    "    if user not in expected_dict: \n",
    "      expected_dict[user] = []\n",
    "      user_relevance[user] = -1\n",
    "    user_relevance[user] += 1\n",
    "    expected_dict[user].append([item, user_relevance[user]])\n",
    "  expected_dict = invert_preference(expected_dict) \n",
    "\n",
    "\n",
    "  # create a dict with the pairs and relevance in relation to the user\n",
    "  user_relevance = {}\n",
    "  for pair in recomendation:\n",
    "    pair = pair[:-1]\n",
    "    user, item = pair.split(',')\n",
    "    if user not in user_relevance: user_relevance[user] = -1\n",
    "    user_relevance[user] += 1\n",
    "    recomendation_dict[pair] = user_relevance[user]\n",
    "  # print(recomendation_dict)\n",
    "  recomendation_dict = invert_preference2(recomendation_dict, user_relevance)\n",
    "\n",
    "  # match the order of the true relevance to the predicted relevance\n",
    "  true_relevance = []\n",
    "  expected_relevance = []\n",
    "  for user in expected_dict.keys():\n",
    "    for item_relevance in expected_dict[user]:\n",
    "      item, relevance = item_relevance\n",
    "      true_relevance.append(relevance)\n",
    "      expected_relevance.append(recomendation_dict[user + ',' + item])      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  return true_relevance, expected_relevance\n",
    "\n",
    "def discount_cumulative_gain(recomendation, expected):\n",
    "  #true_relevance, expected_relevance =\n",
    "  # return get_relevance(recomendation, expected)\n",
    "  true_relevance, expected_relevance = get_relevance(recomendation, expected)\n",
    "  \n",
    "  return ndcg_score(np.array([true_relevance]), np.array([expected_relevance]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "\n",
    "# Separate test and train\n",
    "test, train = ut.read_ratings(test_size=.33)\n",
    "# put test in the same recomendation format\n",
    "test_recomendation = eval.test_to_recomendation(test)\n",
    "# Make recommendations\n",
    "recomendation = trivial.trivial_recomendation(train, test[2].keys(),user_mean=True)\n",
    "# Calculate nDCG\n",
    "discount_cumulative_gain(recomendation, test_recomendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164930, 494790)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[2]), len(train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2f62cb4564c84f0fc417a0719a1997c26b07566098f1a388516455a2c51c4d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
